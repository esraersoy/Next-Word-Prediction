{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "443f4d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "700358203a4548658c0f16f05c5a648f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9c3a2a35dcf44a3a91fe4c8d49300cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "289525e970be4d24a7b6ef5023cc1c57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3ca75bda9704aac8bf42e864ce9fd93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/511M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TFBaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=<tf.Tensor: shape=(1, 7, 768), dtype=float32, numpy=\n",
       "array([[[ 0.08028892,  0.15121321, -0.2958817 , ..., -0.25193146,\n",
       "          0.10468219,  0.46184197],\n",
       "        [ 0.23416208, -0.01264843, -0.2747215 , ...,  0.17610902,\n",
       "          0.38892975, -0.2551906 ],\n",
       "        [ 0.47130805,  0.02673543, -0.17008346, ..., -0.5424892 ,\n",
       "          0.14111695, -0.23771217],\n",
       "        ...,\n",
       "        [ 0.03444475, -0.32429618,  0.07769899, ..., -0.02780228,\n",
       "          0.08623265, -0.8596272 ],\n",
       "        [ 0.03843497, -0.07758588, -0.96168417, ..., -0.03568524,\n",
       "          0.27894577, -0.13651596],\n",
       "        [ 0.8725083 , -0.02664122, -0.5582643 , ...,  0.03990697,\n",
       "         -0.62972516, -0.35996273]]], dtype=float32)>, pooler_output=<tf.Tensor: shape=(1, 768), dtype=float32, numpy=\n",
       "array([[-9.12194133e-01, -4.65130001e-01, -7.82819688e-01,\n",
       "         8.21622789e-01,  3.97013754e-01, -1.70064911e-01,\n",
       "         9.12612855e-01,  3.89790773e-01, -6.42275691e-01,\n",
       "        -9.99989569e-01, -4.05981779e-01,  9.16177213e-01,\n",
       "         9.82879460e-01,  4.85537857e-01,  9.54959333e-01,\n",
       "        -7.83026099e-01, -3.84005845e-01, -7.01134562e-01,\n",
       "         3.22712570e-01, -5.89427054e-01,  6.61489785e-01,\n",
       "         9.99873161e-01,  8.44051316e-02,  3.64988685e-01,\n",
       "         5.03401995e-01,  9.71586347e-01, -7.92360246e-01,\n",
       "         9.46552455e-01,  9.69521523e-01,  7.40193844e-01,\n",
       "        -7.13110387e-01,  1.81244150e-01, -9.89764333e-01,\n",
       "        -2.38705680e-01, -8.29699457e-01, -9.93903220e-01,\n",
       "         4.42899793e-01, -7.60664761e-01, -3.58995385e-02,\n",
       "        -8.97208869e-04, -9.08483624e-01,  2.77857810e-01,\n",
       "         9.99965906e-01, -1.87093481e-01,  4.24700528e-01,\n",
       "        -4.12201822e-01, -1.00000000e+00,  3.58719200e-01,\n",
       "        -9.06926990e-01,  8.64178658e-01,  8.09156477e-01,\n",
       "         7.31290579e-01,  2.34576613e-01,  4.89301711e-01,\n",
       "         5.22080779e-01, -6.45095259e-02, -9.78429690e-02,\n",
       "         1.87285632e-01, -3.20059925e-01, -6.24049604e-01,\n",
       "        -6.94038808e-01,  5.22199929e-01, -7.50504553e-01,\n",
       "        -9.09498155e-01,  8.22766960e-01,  6.91956162e-01,\n",
       "        -2.41125181e-01, -3.01580548e-01, -1.01382762e-01,\n",
       "        -9.85450204e-03,  9.14390087e-01,  2.94058502e-01,\n",
       "        -5.55001311e-02, -8.63219619e-01,  5.03606200e-01,\n",
       "         3.27033579e-01, -6.88820362e-01,  1.00000000e+00,\n",
       "        -6.85027778e-01, -9.78542984e-01,  6.43473983e-01,\n",
       "         7.32074857e-01,  6.20161295e-01, -1.77453950e-01,\n",
       "         3.44909996e-01, -1.00000000e+00,  5.34000397e-01,\n",
       "        -8.93366113e-02, -9.89512444e-01,  3.39195490e-01,\n",
       "         5.10659695e-01, -2.78146863e-01,  3.07062656e-01,\n",
       "         6.17719173e-01, -6.22215569e-01, -4.07533109e-01,\n",
       "        -3.41529399e-01, -7.34015465e-01, -2.97462374e-01,\n",
       "        -2.48649657e-01,  1.18580051e-01, -3.32759678e-01,\n",
       "        -4.44970131e-01, -4.17622566e-01,  3.69151384e-01,\n",
       "        -5.65027058e-01, -5.57305396e-01,  4.37803507e-01,\n",
       "         4.85477708e-02,  7.16958821e-01,  5.01106918e-01,\n",
       "        -3.88244092e-01,  4.95003879e-01, -9.61081207e-01,\n",
       "         6.91329539e-01, -4.46451604e-01, -9.89094496e-01,\n",
       "        -6.39721811e-01, -9.87725139e-01,  7.12389171e-01,\n",
       "        -1.85395643e-01, -2.15142190e-01,  9.68219280e-01,\n",
       "         1.01951286e-01,  4.92367923e-01, -2.46358007e-01,\n",
       "        -8.71310592e-01, -1.00000000e+00, -5.96226513e-01,\n",
       "        -5.93204319e-01, -2.64670193e-01, -3.57765317e-01,\n",
       "        -9.81413424e-01, -9.67414320e-01,  7.13513911e-01,\n",
       "         9.56567228e-01,  2.57266104e-01,  9.99882638e-01,\n",
       "        -3.95130545e-01,  9.50217009e-01, -2.92645484e-01,\n",
       "        -6.94030464e-01,  5.49113512e-01, -5.58755219e-01,\n",
       "         6.98332131e-01,  4.45128828e-01, -6.03896141e-01,\n",
       "         2.39661440e-01, -2.37189546e-01,  3.69278669e-01,\n",
       "        -6.77165270e-01, -2.81072557e-01, -6.56344652e-01,\n",
       "        -9.47624326e-01, -4.13264722e-01,  9.49585497e-01,\n",
       "        -4.19431925e-01, -8.98006558e-01,  5.39930463e-02,\n",
       "        -2.90090680e-01, -5.00682473e-01,  8.49247932e-01,\n",
       "         6.33127153e-01,  4.21263665e-01, -4.11020070e-01,\n",
       "         4.41679269e-01,  2.03890696e-01,  6.09368086e-01,\n",
       "        -8.91355574e-01, -9.66667086e-02,  4.99302089e-01,\n",
       "        -3.73224169e-01, -7.52190113e-01, -9.79604363e-01,\n",
       "        -4.29314286e-01,  6.22032285e-01,  9.91345823e-01,\n",
       "         8.09553087e-01,  3.22394878e-01,  7.52792597e-01,\n",
       "        -3.40485394e-01,  7.17572987e-01, -9.57687378e-01,\n",
       "         9.83055413e-01, -1.98900580e-01,  4.01103705e-01,\n",
       "        -9.05489624e-02,  2.11052269e-01, -8.86857033e-01,\n",
       "         3.17337476e-02,  8.52279603e-01, -4.68425661e-01,\n",
       "        -8.48675132e-01, -1.27600446e-01, -5.32778203e-01,\n",
       "        -4.59407032e-01, -6.29803121e-01,  5.53368866e-01,\n",
       "        -2.97468662e-01, -3.47707540e-01, -3.78717370e-02,\n",
       "         9.36727524e-01,  9.80636060e-01,  7.84565449e-01,\n",
       "        -3.48804854e-02,  7.38312244e-01, -8.98917079e-01,\n",
       "        -5.67553997e-01,  1.45331502e-01,  3.55438113e-01,\n",
       "         5.85901774e-02,  9.95094776e-01, -5.83436310e-01,\n",
       "        -1.22314431e-01, -9.45317209e-01, -9.86173391e-01,\n",
       "         4.73642126e-02, -9.33686435e-01, -8.33264664e-02,\n",
       "        -6.87923670e-01,  7.20985770e-01,  1.99828774e-01,\n",
       "         4.38833326e-01,  5.66968203e-01, -9.82954025e-01,\n",
       "        -8.43831062e-01,  4.36373025e-01, -5.30585945e-01,\n",
       "         4.67529804e-01, -3.08492362e-01,  6.94286227e-01,\n",
       "         8.60836387e-01, -6.51996076e-01,  7.63524294e-01,\n",
       "         9.26750243e-01, -7.33203828e-01, -7.72833943e-01,\n",
       "         8.35551560e-01, -2.87914634e-01,  9.01314557e-01,\n",
       "        -6.81643248e-01,  9.86815929e-01,  8.55806887e-01,\n",
       "         7.36027181e-01, -9.29105818e-01, -6.07813478e-01,\n",
       "        -8.70558560e-01, -6.59482598e-01, -9.48802978e-02,\n",
       "         2.36522593e-02,  8.06313872e-01,  6.81020200e-01,\n",
       "         4.12568122e-01,  3.74080122e-01, -6.61993206e-01,\n",
       "         9.98327136e-01, -7.24892020e-01, -9.60136890e-01,\n",
       "        -1.43436462e-01, -1.65338740e-01, -9.88913298e-01,\n",
       "         7.08354533e-01,  4.11090463e-01,  2.98824552e-02,\n",
       "        -4.49128777e-01, -7.49724090e-01, -9.67510700e-01,\n",
       "         8.56345057e-01,  1.72133610e-01,  9.87215340e-01,\n",
       "        -9.74929258e-02, -9.31751847e-01, -5.96080184e-01,\n",
       "        -9.28842545e-01, -1.34902343e-01, -2.04456910e-01,\n",
       "        -1.70206726e-01, -1.41111165e-01, -9.65067327e-01,\n",
       "         5.79828620e-01,  6.05211616e-01,  5.80103219e-01,\n",
       "        -7.48819053e-01,  9.99243021e-01,  1.00000000e+00,\n",
       "         9.74740386e-01,  9.05593991e-01,  9.36240673e-01,\n",
       "        -9.99396324e-01, -4.33216482e-01,  9.99996960e-01,\n",
       "        -9.79959548e-01, -1.00000000e+00, -9.41763878e-01,\n",
       "        -6.07842088e-01,  4.10305381e-01, -1.00000000e+00,\n",
       "        -3.24322224e-01, -1.08555868e-01, -9.23478067e-01,\n",
       "         6.23162389e-01,  9.79867518e-01,  9.94296193e-01,\n",
       "        -1.00000000e+00,  8.64080548e-01,  9.48169589e-01,\n",
       "        -7.36034751e-01,  9.28206265e-01, -4.63176996e-01,\n",
       "         9.74921227e-01,  5.73867619e-01,  4.54574734e-01,\n",
       "        -3.17216873e-01,  4.65868026e-01, -8.83119524e-01,\n",
       "        -8.91104937e-01, -4.38782692e-01, -5.78261137e-01,\n",
       "         9.91485476e-01,  2.08610967e-01, -8.17817628e-01,\n",
       "        -9.16412175e-01,  3.59929174e-01, -1.27946496e-01,\n",
       "        -3.50763232e-01, -9.65379655e-01, -2.50171125e-01,\n",
       "         4.61759418e-01,  8.13009441e-01,  1.27034828e-01,\n",
       "         4.12794381e-01, -7.34422684e-01,  3.07344079e-01,\n",
       "        -2.18692139e-01,  3.62604856e-01,  7.35854447e-01,\n",
       "        -9.57244813e-01, -4.72567648e-01,  4.80491892e-02,\n",
       "        -1.87629312e-01, -5.35037637e-01, -9.64923561e-01,\n",
       "         9.66685653e-01, -4.66813296e-01,  8.16971064e-01,\n",
       "         1.00000000e+00,  1.88425690e-01, -9.01776075e-01,\n",
       "         5.83910882e-01,  2.85855353e-01, -3.00889671e-01,\n",
       "         1.00000000e+00,  7.58472681e-01, -9.78803098e-01,\n",
       "        -5.98413348e-01,  5.41762829e-01, -6.01011157e-01,\n",
       "        -6.55730307e-01,  9.99617219e-01, -2.16889799e-01,\n",
       "        -5.49484849e-01, -1.73332870e-01,  9.79393363e-01,\n",
       "        -9.90652502e-01,  9.85476315e-01, -9.43579793e-01,\n",
       "        -9.73015487e-01,  9.71591234e-01,  9.42817092e-01,\n",
       "        -5.88217080e-01, -6.79521024e-01,  1.82877511e-01,\n",
       "        -6.70910060e-01,  3.09226543e-01, -9.60624754e-01,\n",
       "         6.89943492e-01,  6.42056763e-01, -1.85510576e-01,\n",
       "         8.89412701e-01, -8.49336386e-01, -6.15935445e-01,\n",
       "         3.31066936e-01, -5.10306120e-01,  2.45749392e-02,\n",
       "         8.61597300e-01,  5.87939262e-01, -3.17957014e-01,\n",
       "         6.74004480e-02, -3.65358710e-01, -5.06835222e-01,\n",
       "        -9.81958628e-01,  2.94055611e-01,  1.00000000e+00,\n",
       "        -1.49871156e-01,  4.65095341e-01, -4.75098431e-01,\n",
       "        -9.23044309e-02, -1.56872869e-01,  5.41375101e-01,\n",
       "         6.22453809e-01, -3.80169809e-01, -8.92620564e-01,\n",
       "         6.69619560e-01, -9.57036734e-01, -9.85303104e-01,\n",
       "         7.65077949e-01,  1.96356699e-01, -4.10020441e-01,\n",
       "         9.99994993e-01,  4.25323516e-01,  1.67908058e-01,\n",
       "         2.66687423e-01,  9.68002796e-01,  4.61057648e-02,\n",
       "         6.43142641e-01,  8.08728874e-01,  9.84400868e-01,\n",
       "        -3.00420254e-01,  6.35569632e-01,  8.35399985e-01,\n",
       "        -8.33405256e-01, -4.41126078e-01, -7.07276344e-01,\n",
       "        -6.09708540e-02, -9.21156347e-01, -2.86672134e-02,\n",
       "        -9.52448547e-01,  9.68564630e-01,  8.86252880e-01,\n",
       "         4.46512222e-01,  2.95274377e-01,  4.37649906e-01,\n",
       "         1.00000000e+00, -5.53848624e-01,  6.10877156e-01,\n",
       "        -2.50482619e-01,  8.35648477e-01, -9.98815835e-01,\n",
       "        -8.91016781e-01, -4.23940271e-01, -8.26155096e-02,\n",
       "        -6.67023838e-01, -3.88446033e-01,  3.70141447e-01,\n",
       "        -9.67954338e-01,  7.34459639e-01,  5.56555212e-01,\n",
       "        -9.90057886e-01, -9.91742909e-01, -4.67292331e-02,\n",
       "         8.56603980e-01,  1.92017227e-01, -9.64878082e-01,\n",
       "        -8.05124342e-01, -6.45741343e-01,  6.07806981e-01,\n",
       "        -3.50718141e-01, -9.48981345e-01, -1.17111459e-01,\n",
       "        -4.19175208e-01,  4.97700542e-01, -2.98649341e-01,\n",
       "         6.31694436e-01,  7.67989099e-01,  7.06489742e-01,\n",
       "        -3.64229828e-01, -1.22070514e-01, -1.19380385e-01,\n",
       "        -8.34836185e-01,  8.70086551e-01, -8.72486055e-01,\n",
       "        -8.29559803e-01, -2.57024854e-01,  1.00000000e+00,\n",
       "        -5.97290456e-01,  8.18193197e-01,  7.82130480e-01,\n",
       "         7.33532012e-01, -2.11709931e-01,  2.93759763e-01,\n",
       "         8.42068970e-01,  3.46007913e-01, -6.75484538e-01,\n",
       "        -7.78137267e-01, -6.48506343e-01, -4.96935099e-01,\n",
       "         7.22773850e-01,  1.02224931e-01,  6.53423846e-01,\n",
       "         8.17332864e-01,  6.57743216e-01,  7.90254027e-02,\n",
       "        -9.61135700e-02,  3.56339328e-02,  9.99684155e-01,\n",
       "        -1.70268461e-01, -1.42407268e-01, -5.54179072e-01,\n",
       "        -9.26166251e-02, -4.42653745e-01, -3.45320165e-01,\n",
       "         1.00000000e+00,  3.72473508e-01,  2.63392150e-01,\n",
       "        -9.92039323e-01, -7.21979439e-01, -9.28357303e-01,\n",
       "         9.99998331e-01,  8.16853285e-01, -8.10625076e-01,\n",
       "         7.63324678e-01,  5.94349146e-01, -1.85225978e-01,\n",
       "         7.89162755e-01, -2.31524482e-01, -3.51116449e-01,\n",
       "         3.06838691e-01,  1.75067857e-01,  9.65733230e-01,\n",
       "        -5.95348358e-01, -9.72869456e-01, -6.52988791e-01,\n",
       "         4.92992431e-01, -9.72954154e-01,  9.99647260e-01,\n",
       "        -6.30016029e-01, -3.60002875e-01, -4.94498879e-01,\n",
       "        -2.09129062e-02,  2.13339224e-01, -1.08148739e-01,\n",
       "        -9.85599399e-01, -2.84587175e-01,  2.09222719e-01,\n",
       "         9.58026469e-01,  3.05069327e-01, -6.56376183e-01,\n",
       "        -8.91886532e-01,  6.05625808e-01,  6.85940921e-01,\n",
       "        -8.56971979e-01, -9.48431671e-01,  9.66041803e-01,\n",
       "        -9.86506701e-01,  5.95333338e-01,  1.00000000e+00,\n",
       "         4.10938382e-01, -2.00960249e-01,  2.84745812e-01,\n",
       "        -4.77343172e-01,  3.66562337e-01,  1.05506949e-01,\n",
       "         7.86747098e-01, -9.62306917e-01, -3.13416779e-01,\n",
       "        -1.95476413e-01,  3.41783196e-01, -1.36345059e-01,\n",
       "        -7.78241307e-02,  7.24700987e-01,  2.35848218e-01,\n",
       "        -6.26053751e-01, -6.76546574e-01, -1.31004736e-01,\n",
       "         4.78354365e-01,  8.93113434e-01, -3.15594077e-01,\n",
       "        -2.57850319e-01,  2.07742840e-01, -1.56096831e-01,\n",
       "        -9.27291751e-01, -3.10133338e-01, -5.22104800e-01,\n",
       "        -9.99969780e-01,  7.62887180e-01, -1.00000000e+00,\n",
       "         2.85600036e-01,  1.36715755e-01, -3.34710449e-01,\n",
       "         8.75657260e-01,  1.74952537e-01,  6.06902540e-01,\n",
       "        -8.12426507e-01, -7.38827884e-01,  5.85770369e-01,\n",
       "         7.97500730e-01, -3.02781582e-01, -4.25508261e-01,\n",
       "        -7.60548890e-01,  3.20150375e-01, -5.29592074e-02,\n",
       "         1.14569664e-01, -5.26991606e-01,  8.02930176e-01,\n",
       "        -2.56563544e-01,  1.00000000e+00,  1.84161440e-01,\n",
       "        -7.34148622e-01, -9.76390660e-01,  1.99780703e-01,\n",
       "        -3.24812233e-01,  1.00000000e+00, -9.19088840e-01,\n",
       "        -9.53950167e-01,  4.57780123e-01, -6.99008524e-01,\n",
       "        -8.62827301e-01,  3.75877142e-01,  9.85892490e-02,\n",
       "        -7.20714211e-01, -8.52631390e-01,  9.65725899e-01,\n",
       "         8.88065279e-01, -6.25211239e-01,  4.93703723e-01,\n",
       "        -3.88436407e-01, -4.93680060e-01,  1.26031205e-01,\n",
       "         6.71827614e-01,  9.87045050e-01,  4.79890943e-01,\n",
       "         9.19085205e-01,  3.80193979e-01, -1.37165204e-01,\n",
       "         9.77536142e-01,  2.70553291e-01,  4.87062275e-01,\n",
       "         1.14372402e-01,  1.00000000e+00,  4.23397094e-01,\n",
       "        -9.15518463e-01,  2.83579260e-01, -9.81710017e-01,\n",
       "        -3.32319319e-01, -9.55201030e-01,  4.02947098e-01,\n",
       "         2.71060854e-01,  8.93180430e-01, -1.97018459e-01,\n",
       "         9.73957479e-01, -6.24774933e-01,  1.03418333e-02,\n",
       "        -5.49698532e-01, -2.77338833e-01,  5.21651566e-01,\n",
       "        -9.27219868e-01, -9.85252976e-01, -9.88015890e-01,\n",
       "         5.57976007e-01, -4.86545324e-01, -1.08080916e-01,\n",
       "         2.10870996e-01,  1.97109893e-01,  4.98528659e-01,\n",
       "         4.65485215e-01, -1.00000000e+00,  9.42046344e-01,\n",
       "         4.81074542e-01,  8.70776236e-01,  9.61025536e-01,\n",
       "         6.18771553e-01,  4.91537154e-01,  2.91979015e-01,\n",
       "        -9.88478601e-01, -9.78755176e-01, -3.60117316e-01,\n",
       "        -2.95163333e-01,  8.08455050e-01,  6.76469862e-01,\n",
       "         9.15156722e-01,  4.87882912e-01, -5.86643994e-01,\n",
       "        -2.00823829e-01, -3.98917288e-01, -4.05923337e-01,\n",
       "        -9.93497372e-01,  4.99726415e-01, -4.78377998e-01,\n",
       "        -9.66476142e-01,  9.66432214e-01, -3.14463168e-01,\n",
       "        -2.44865403e-01,  1.31485403e-01, -7.33082414e-01,\n",
       "         9.30117190e-01,  7.99596727e-01,  4.17261809e-01,\n",
       "         1.11021057e-01,  4.85104620e-01,  9.02822912e-01,\n",
       "         9.63871360e-01,  9.86755490e-01, -7.57505119e-01,\n",
       "         8.66125047e-01, -5.79733014e-01,  5.47392309e-01,\n",
       "         7.45227337e-01, -9.33294833e-01,  1.57361761e-01,\n",
       "         4.79040354e-01, -4.67644602e-01,  3.70034903e-01,\n",
       "        -2.35369846e-01, -9.76467311e-01,  7.50243366e-01,\n",
       "        -3.90048325e-01,  5.61933815e-01, -4.68565851e-01,\n",
       "         2.44528931e-02, -4.61893946e-01, -1.54346183e-01,\n",
       "        -7.89577663e-01, -6.97990596e-01,  6.80922747e-01,\n",
       "         4.97118652e-01,  9.11205053e-01,  6.76428735e-01,\n",
       "        -4.47207540e-02, -7.63250172e-01, -1.80849999e-01,\n",
       "        -6.96829617e-01, -9.32839334e-01,  9.44370627e-01,\n",
       "        -1.15403548e-01, -3.00995171e-01,  4.59492534e-01,\n",
       "        -6.42918050e-02,  8.63618910e-01, -2.30433941e-02,\n",
       "        -4.11490023e-01, -3.66075486e-01, -7.43201613e-01,\n",
       "         9.05537248e-01, -5.21893203e-01, -5.79696774e-01,\n",
       "        -6.05880201e-01,  7.39130855e-01,  3.81491452e-01,\n",
       "         9.99937057e-01, -6.69422269e-01, -8.15648913e-01,\n",
       "        -3.34262967e-01, -3.91324192e-01,  4.99149114e-01,\n",
       "        -5.12345433e-01, -1.00000000e+00,  4.50567216e-01,\n",
       "        -3.06365788e-01,  6.37343407e-01, -4.90197778e-01,\n",
       "         6.70176148e-01, -6.51100039e-01, -9.81978238e-01,\n",
       "        -2.90910870e-01,  2.98811227e-01,  5.79854012e-01,\n",
       "        -5.53336382e-01, -5.46859920e-01,  6.49583340e-01,\n",
       "        -9.42809656e-02,  9.25615609e-01,  8.81329656e-01,\n",
       "        -5.60298264e-01,  2.73175776e-01,  6.90982282e-01,\n",
       "        -5.81949472e-01, -7.71385074e-01,  9.27574635e-01]], dtype=float32)>, past_key_values=None, hidden_states=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing library\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "#defining tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "#instantiating the model\n",
    "model = TFBertModel.from_pretrained(\"bert-base-uncased\")\n",
    "text = \"What is your name?\"\n",
    "#extracting features\n",
    "encoded_input = tokenizer(text, return_tensors='tf')\n",
    "model(encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "921e2135",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForMaskedLM.\n",
      "\n",
      "All the layers of TFBertForMaskedLM were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "035b3dc7f3384ee39002a97afb258d25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.05977549031376839,\n",
       "  'token': 5160,\n",
       "  'token_str': 'lawyer',\n",
       "  'sequence': 'he can work as a lawyer.'},\n",
       " {'score': 0.04769814386963844,\n",
       "  'token': 15893,\n",
       "  'token_str': 'mechanic',\n",
       "  'sequence': 'he can work as a mechanic.'},\n",
       " {'score': 0.034236401319503784,\n",
       "  'token': 10533,\n",
       "  'token_str': 'carpenter',\n",
       "  'sequence': 'he can work as a carpenter.'},\n",
       " {'score': 0.02049887366592884,\n",
       "  'token': 3460,\n",
       "  'token_str': 'doctor',\n",
       "  'sequence': 'he can work as a doctor.'},\n",
       " {'score': 0.01972660981118679,\n",
       "  'token': 5268,\n",
       "  'token_str': 'soldier',\n",
       "  'sequence': 'he can work as a soldier.'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "model = pipeline('fill-mask', model='bert-base-uncased')\n",
    "pred = model(\"he can work as a [MASK].\")\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da0caff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'purpose'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model(\"what is your [MASK].\")\n",
    "pred[2]['token_str']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f73b4f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x000001CE00006F78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x000001CE00006F78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TFBertForMaskedLM.call of <transformers.models.bert.modeling_tf_bert.TFBertForMaskedLM object at 0x000001CE0218AD48>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertForMaskedLM.call of <transformers.models.bert.modeling_tf_bert.TFBertForMaskedLM object at 0x000001CE0218AD48>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TFBertMainLayer.call of <transformers.models.bert.modeling_tf_bert.TFBertMainLayer object at 0x000001CE0224C748>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertMainLayer.call of <transformers.models.bert.modeling_tf_bert.TFBertMainLayer object at 0x000001CE0224C748>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TFBertEmbeddings.call of <transformers.models.bert.modeling_tf_bert.TFBertEmbeddings object at 0x000001CE02240CC8>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertEmbeddings.call of <transformers.models.bert.modeling_tf_bert.TFBertEmbeddings object at 0x000001CE02240CC8>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TFBertEncoder.call of <transformers.models.bert.modeling_tf_bert.TFBertEncoder object at 0x000001CE021B0888>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertEncoder.call of <transformers.models.bert.modeling_tf_bert.TFBertEncoder object at 0x000001CE021B0888>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TFBertLayer.call of <transformers.models.bert.modeling_tf_bert.TFBertLayer object at 0x000001CE021B0F48>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertLayer.call of <transformers.models.bert.modeling_tf_bert.TFBertLayer object at 0x000001CE021B0F48>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TFBertAttention.call of <transformers.models.bert.modeling_tf_bert.TFBertAttention object at 0x000001CE02195448>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertAttention.call of <transformers.models.bert.modeling_tf_bert.TFBertAttention object at 0x000001CE02195448>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TFBertSelfAttention.call of <transformers.models.bert.modeling_tf_bert.TFBertSelfAttention object at 0x000001CE021958C8>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertSelfAttention.call of <transformers.models.bert.modeling_tf_bert.TFBertSelfAttention object at 0x000001CE021958C8>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TFBertSelfOutput.call of <transformers.models.bert.modeling_tf_bert.TFBertSelfOutput object at 0x000001CE021999C8>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <bound method TFBertSelfOutput.call of <transformers.models.bert.modeling_tf_bert.TFBertSelfOutput object at 0x000001CE021999C8>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TFBertIntermediate.call of <transformers.models.bert.modeling_tf_bert.TFBertIntermediate object at 0x000001CE021A1248>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertIntermediate.call of <transformers.models.bert.modeling_tf_bert.TFBertIntermediate object at 0x000001CE021A1248>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TFBertOutput.call of <transformers.models.bert.modeling_tf_bert.TFBertOutput object at 0x000001CE021A1EC8>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertOutput.call of <transformers.models.bert.modeling_tf_bert.TFBertOutput object at 0x000001CE021A1EC8>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TFBertMLMHead.call of <transformers.models.bert.modeling_tf_bert.TFBertMLMHead object at 0x000001CE022F1208>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertMLMHead.call of <transformers.models.bert.modeling_tf_bert.TFBertMLMHead object at 0x000001CE022F1208>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TFBertLMPredictionHead.call of <transformers.models.bert.modeling_tf_bert.TFBertLMPredictionHead object at 0x000001CE022F16C8>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertLMPredictionHead.call of <transformers.models.bert.modeling_tf_bert.TFBertLMPredictionHead object at 0x000001CE022F16C8>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TFBertPredictionHeadTransform.call of <transformers.models.bert.modeling_tf_bert.TFBertPredictionHeadTransform object at 0x000001CE022F1AC8>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertPredictionHeadTransform.call of <transformers.models.bert.modeling_tf_bert.TFBertPredictionHeadTransform object at 0x000001CE022F1AC8>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TFPreTrainedModel.serving of <tensorflow.python.eager.function.TfMethodTarget object at 0x000001CE0777DB08>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFPreTrainedModel.serving of <tensorflow.python.eager.function.TfMethodTarget object at 0x000001CE0777DB08>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000001CE28259CA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000001CE28259CA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, predictions_layer_call_fn while saving (showing 5 of 424). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://ec43337d-514a-4f1f-ae25-79487c715391/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://ec43337d-514a-4f1f-ae25-79487c715391/assets\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_file = open('Bert.pkl', 'wb')     \n",
    "pickle.dump(model, pickle_file)\n",
    "pickle_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3700fce8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
